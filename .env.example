# Multi-Agent Investment Committee - Environment Variables
# Copy this file to .env and fill in your values

# ╔══════════════════════════════════════════════════════════════╗
# ║  LLM Provider — pick ONE                                    ║
# ║  Options: anthropic, google, openai, huggingface, ollama     ║
# ╚══════════════════════════════════════════════════════════════╝
LLM_PROVIDER=anthropic

# ── Anthropic (Claude) ──────────────────────────────────────────
ANTHROPIC_API_KEY=sk-ant-your_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# ── Google (Gemini) ─────────────────────────────────────────────
GOOGLE_API_KEY=your_google_ai_key_here
GOOGLE_MODEL=gemini-2.0-flash

# ── OpenAI (optional — install with: pip install -e ".[openai]")
OPENAI_API_KEY=sk-your_key_here
OPENAI_MODEL=gpt-4o-mini

# ── Hugging Face ────────────────────────────────────────────────
HF_TOKEN=hf_your_token_here
HF_MODEL=Qwen/Qwen2.5-72B-Instruct

# ── Ollama (local open-source — install with: pip install -e ".[ollama]")
# Start Ollama first: ollama serve
# Pull a model: ollama pull llama3.1:8b
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# ── Reasoning parameters ───────────────────────────────────────
MAX_DEBATE_ROUNDS=2
MAX_TOKENS_PER_AGENT=4096
TEMPERATURE=0.7
