# Multi-Agent Investment Committee - Environment Variables
# Copy this file to .env and fill in your values

# ╔══════════════════════════════════════════════════════════════╗
# ║  LLM Provider — pick ONE                                    ║
# ║  Options: anthropic, google, openai, deepseek,               ║
# ║           huggingface, ollama                                ║
# ║                                                              ║
# ║  If no API keys are set, defaults to Ollama (local).         ║
# ╚══════════════════════════════════════════════════════════════╝
LLM_PROVIDER=anthropic

# ── Anthropic (Claude) ──────────────────────────────────────────
ANTHROPIC_API_KEY=sk-ant-your_key_here
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# ── Google (Gemini) ─────────────────────────────────────────────
GOOGLE_API_KEY=your_google_ai_key_here
GOOGLE_MODEL=gemini-2.0-flash

# ── OpenAI (optional — install with: pip install -e ".[openai]")
OPENAI_API_KEY=sk-your_key_here
OPENAI_MODEL=gpt-4o-mini

# ── DeepSeek (optional — uses OpenAI package: pip install -e ".[deepseek]")
DEEPSEEK_API_KEY=your_deepseek_key_here
DEEPSEEK_MODEL=deepseek-chat

# ── Hugging Face ────────────────────────────────────────────────
HF_TOKEN=hf_your_token_here
HF_MODEL=Qwen/Qwen2.5-72B-Instruct

# ── Ollama (local open-source — install with: pip install -e ".[ollama]")
# Start Ollama first: ollama serve
# Pull a model: ollama pull llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# ── Reasoning parameters ───────────────────────────────────────
MAX_DEBATE_ROUNDS=2
MAX_TOKENS_PER_AGENT=4096
MAX_TOOL_CALLS_PER_AGENT=5
TEMPERATURE=0.7

# ── Rate Limiting (Anthropic Tier 1) ─────────────────────────
# Applied automatically for Anthropic. Set to 0 to disable.
# Defaults are 85% of Tier 1 limits for safety margin.
# Upgrade to higher tier → increase these values.
RATE_LIMIT_RPM=45
RATE_LIMIT_INPUT_TPM=25000
RATE_LIMIT_OUTPUT_TPM=7000

# ── v3 Features ───────────────────────────────────────────────
# Sentiment extraction, head-trader PM, portfolio strategy, and
# T signal are enabled by default. No additional config needed.
#
# T signal = direction * entropy-adjusted confidence
#   Computed automatically from PM output (position_direction, raw_confidence)
#   Logged to runs/ JSONL for downstream RL consumption
#
# HITL mode (Review Before PM) is enabled by default:
# ENABLE_HITL=true
